#!/usr/bin/env python3
"""
ç¬¬4èŠ‚ï¼šé€šè¿‡è¿ç»­å°æ³¢å˜æ¢è¿›è¡Œæ—¶é¢‘åˆ†è§£æ¨¡å—
"""

import numpy as np
import matplotlib.pyplot as plt
import pywt
from scipy import signal
import warnings
warnings.filterwarnings('ignore')

class WaveletTransformProcessor:
    """è¿ç»­å°æ³¢å˜æ¢å¤„ç†å™¨"""
    
    def __init__(self, analyzer):
        """åˆå§‹åŒ–å°æ³¢å˜æ¢å¤„ç†å™¨"""
        self.analyzer = analyzer
        self.sampling_rate = 100000  # 100 kHz (10å¾®ç§’é‡‡æ ·é—´éš”)
        self.target_freq_range = (1, 30000)  # 1 Hz åˆ° 30 kHz
        self.wavelet_name = 'cmor1.5-1.0'  # å¤æ•°Morletå°æ³¢
        self.scales = None
        self.frequencies = None
        self.scalograms_dataset = None
        
    def design_wavelet_scales(self):
        """è®¾è®¡å°æ³¢å°ºåº¦ä»¥è¦†ç›–ç›®æ ‡é¢‘ç‡èŒƒå›´"""
        print("æ­£åœ¨è®¾è®¡å°æ³¢å°ºåº¦...")
        
        # é‡‡æ ·å‘¨æœŸ
        sampling_period = 1.0 / self.sampling_rate
        
        # ç›®æ ‡é¢‘ç‡èŒƒå›´
        freq_min, freq_max = self.target_freq_range
        
        print(f"  é‡‡æ ·ç‡: {self.sampling_rate/1000:.0f} kHz")
        print(f"  ç›®æ ‡é¢‘ç‡èŒƒå›´: {freq_min} Hz - {freq_max/1000:.0f} kHz")
        print(f"  é€‰æ‹©çš„å°æ³¢: {self.wavelet_name}")
        
        # è®¡ç®—å¯¹åº”çš„å°ºåº¦èŒƒå›´
        # ä½¿ç”¨pywt.scale2frequencyå‡½æ•°è¿›è¡Œè½¬æ¢
        # f = pywt.scale2frequency(wavelet, scale) / sampling_period
        
        # ä»æœ€é«˜é¢‘ç‡åˆ°æœ€ä½é¢‘ç‡ï¼Œå¯¹æ•°é—´éš”ç”Ÿæˆå°ºåº¦
        # æ›´é«˜çš„é¢‘ç‡å¯¹åº”æ›´å°çš„å°ºåº¦
        scale_max = pywt.scale2frequency(self.wavelet_name, 1) / (freq_min * sampling_period)
        scale_min = pywt.scale2frequency(self.wavelet_name, 1) / (freq_max * sampling_period)
        
        # ç”Ÿæˆå¯¹æ•°é—´éš”çš„å°ºåº¦æ•°ç»„
        n_scales = 200  # å¢åŠ åˆ°200ä¸ªå°ºåº¦ä»¥æé«˜é¢‘ç‡åˆ†è¾¨ç‡
        self.scales = np.logspace(np.log10(scale_min), np.log10(scale_max), n_scales)
        
        # è®¡ç®—å¯¹åº”çš„é¢‘ç‡
        self.frequencies = pywt.scale2frequency(self.wavelet_name, self.scales) / sampling_period
        
        print(f"  ç”Ÿæˆäº† {len(self.scales)} ä¸ªå°ºåº¦")
        print(f"  å®é™…é¢‘ç‡èŒƒå›´: {self.frequencies.min():.1f} Hz - {self.frequencies.max()/1000:.1f} kHz")
        
        # å¯è§†åŒ–å°ºåº¦-é¢‘ç‡å…³ç³»
        self._visualize_scale_frequency_relationship()
        
    def _visualize_scale_frequency_relationship(self):
        """å¯è§†åŒ–å°ºåº¦ä¸é¢‘ç‡çš„å…³ç³»"""
        # æ£€æŸ¥scaleså’Œfrequenciesæ˜¯å¦å·²ç»åˆå§‹åŒ–
        if self.scales is None or self.frequencies is None:
            print("  é”™è¯¯ï¼šå°ºåº¦å’Œé¢‘ç‡å°šæœªåˆå§‹åŒ–ï¼è¯·å…ˆè°ƒç”¨design_wavelet_scales()æ–¹æ³•")
            return
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
        
        # 1. å°ºåº¦åˆ†å¸ƒ
        ax1.semilogx(self.scales, np.arange(len(self.scales)), 'b.-')
        ax1.set_xlabel('Scale')
        ax1.set_ylabel('Scale Index')
        ax1.set_title('Wavelet Scales Distribution')
        ax1.grid(True, alpha=0.3)
        
        # 2. é¢‘ç‡åˆ†å¸ƒ
        ax2.semilogx(self.frequencies, np.arange(len(self.frequencies)), 'r.-')
        ax2.set_xlabel('Frequency (Hz)')
        ax2.set_ylabel('Scale Index')
        ax2.set_title('Corresponding Frequencies Distribution')
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('wavelet_scales_design.png', dpi=300, bbox_inches='tight')
        plt.show()
        print("  å°ºåº¦è®¾è®¡å›¾å·²ä¿å­˜ä¸º wavelet_scales_design.png")
    
    def apply_cwt_to_dataset(self):
        """ç¬¬4.3èŠ‚ï¼šå¯¹æ•´ä¸ªæ•°æ®é›†åº”ç”¨CWTç”Ÿæˆå°ºåº¦å›¾ - åˆ†æ‰¹å¤„ç†ç‰ˆæœ¬"""
        print("æ­£åœ¨å¯¹æ•°æ®é›†åº”ç”¨è¿ç»­å°æ³¢å˜æ¢ï¼ˆåˆ†æ‰¹å¤„ç†ï¼‰...")
        
        # æ£€æŸ¥scaleså’Œfrequenciesæ˜¯å¦å·²ç»åˆå§‹åŒ–
        if self.scales is None or self.frequencies is None:
            raise ValueError("å¿…é¡»å…ˆè°ƒç”¨design_wavelet_scales()æ–¹æ³•æ¥åˆå§‹åŒ–å°ºåº¦å’Œé¢‘ç‡")
        
        # è·å–æ¨¡å‹æ•°æ®é›†
        if not hasattr(self.analyzer, 'target_builder'):
            raise ValueError("å¿…é¡»å…ˆå®Œæˆç¬¬3èŠ‚çš„å›å½’ç›®æ ‡æ„å»ºæ‰èƒ½è¿›è¡ŒCWT")
        
        waveforms = self.analyzer.target_builder.model_dataset['waveforms']
        csi_labels = self.analyzer.target_builder.model_dataset['csi_labels']
        metadata = self.analyzer.target_builder.model_dataset['metadata']
        
        n_samples = len(waveforms)
        n_scales = len(self.scales)
        n_time_samples = waveforms.shape[1]
        
        print(f"  å¤„ç† {n_samples:,} ä¸ªæ³¢å½¢...")
        print(f"  æ³¢å½¢é•¿åº¦: {n_time_samples} ä¸ªæ ·ç‚¹")
        print(f"  å°ºåº¦æ•°é‡: {n_scales}")
        
        # æ£€æµ‹æ˜¯å¦å·²æœ‰åˆé€‚çš„HDF5æ–‡ä»¶ï¼ˆæ–°å¢ï¼‰
        existing_hdf5_files = [
            'scalograms_temp.h5',
            'scalograms_optimized.h5',
            'scalograms_fallback.h5'
        ]
        
        for hdf5_file in existing_hdf5_files:
            try:
                from pathlib import Path
                if Path(hdf5_file).exists():
                    import h5py
                    with h5py.File(hdf5_file, 'r') as f:
                        if 'scalograms' in f:
                            existing_shape = f['scalograms'].shape
                            existing_samples = existing_shape[0]
                            
                            # æ£€æŸ¥æ ·æœ¬æ•°é‡å’Œå°ºåº¦æ•°é‡æ˜¯å¦åŒ¹é…
                            if existing_samples == n_samples and existing_shape[1] == n_scales:
                                print(f"  âœ… å‘ç°åŒ¹é…çš„HDF5æ–‡ä»¶: {hdf5_file}")
                                print(f"      ç°æœ‰æ•°æ®å½¢çŠ¶: {existing_shape}")
                                print(f"  ğŸ“‚ ä½¿ç”¨å·²æœ‰HDF5æ–‡ä»¶ï¼Œè·³è¿‡å°æ³¢å˜æ¢å¤„ç†")
                                
                                # æ„å»ºæ•°æ®é›†å…ƒæ•°æ®
                                self.scalograms_dataset = {
                                    'scalograms_file': hdf5_file,  # ä¿å­˜æ–‡ä»¶è·¯å¾„è€Œä¸æ˜¯æ•°æ®
                                    'n_samples': n_samples,
                                    'shape': existing_shape,
                                    'csi_labels': csi_labels,
                                    'metadata': metadata,
                                    'scales': self.scales,
                                    'frequencies': self.frequencies,
                                    'time_axis': np.arange(n_time_samples) * (1.0 / self.sampling_rate),
                                    'transform_params': {
                                        'wavelet': self.wavelet_name,
                                        'sampling_rate': self.sampling_rate,
                                        'freq_range': self.target_freq_range,
                                        'n_scales': n_scales
                                    }
                                }
                                
                                print(f"  ğŸ“Š æ•°æ®é›†å½¢çŠ¶: {existing_shape}")
                                print(f"  ğŸ’¾ æ•°æ®æ–‡ä»¶: {hdf5_file}")
                                print(f"  ğŸ“» é¢‘ç‡èŒƒå›´: {self.frequencies.min():.1f} Hz - {self.frequencies.max()/1000:.1f} kHz")
                                
                                # è¿›è¡Œå¿«é€Ÿå¯è§†åŒ–ï¼ˆä½¿ç”¨æ ·æœ¬æ•°æ®ï¼‰
                                print("  ğŸ¨ ç”Ÿæˆæ ·æœ¬å¯è§†åŒ–...")
                                with h5py.File(hdf5_file, 'r') as f:
                                    sample_scalograms = f['scalograms'][:min(1000, n_samples)]
                                self._visualize_sample_scalograms_from_hdf5(sample_scalograms)
                                del sample_scalograms
                                
                                return  # ç›´æ¥è¿”å›ï¼Œè·³è¿‡åç»­å¤„ç†
                            else:
                                print(f"  âš ï¸ å‘ç°HDF5æ–‡ä»¶ä½†ç»´åº¦ä¸åŒ¹é…: {hdf5_file}")
                                print(f"      å½“å‰éœ€è¦: ({n_samples}, {n_scales}, {n_time_samples})")
                                print(f"      æ–‡ä»¶ä¸­æœ‰: {existing_shape}")
            except Exception as e:
                print(f"  âš ï¸ æ£€æŸ¥HDF5æ–‡ä»¶å¤±è´¥: {hdf5_file} - {e}")
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„HDF5æ–‡ä»¶ï¼Œç»§ç»­åŸæœ‰çš„å¤„ç†æµç¨‹
        print("  ğŸ”„ æœªæ‰¾åˆ°åŒ¹é…çš„HDF5æ–‡ä»¶ï¼Œå¼€å§‹ç”Ÿæˆæ–°çš„å°ºåº¦å›¾...")
        
        # åˆ†æ‰¹å¤„ç†å‚æ•°
        batch_size = 1000  # æ¯æ‰¹å¤„ç†1000ä¸ªæ ·æœ¬
        n_batches = (n_samples + batch_size - 1) // batch_size
        
        print(f"  ğŸ“¦ åˆ†æ‰¹å¤„ç†: {n_batches} æ‰¹ï¼Œæ¯æ‰¹ {batch_size} æ ·æœ¬")
        
        # å¯¼å…¥h5py
        try:
            import h5py
        except ImportError:
            print("âŒ h5pyæœªå®‰è£…ï¼Œè¯·å®‰è£…ï¼špip install h5py")
            raise ImportError("éœ€è¦h5pyåº“è¿›è¡Œå¤§æ•°æ®é›†å¤„ç†")
        
        # åˆ›å»ºHDF5æ–‡ä»¶
        hdf5_file = 'scalograms_temp.h5'
        print(f"  ğŸ’¾ åˆ›å»ºä¸´æ—¶æ–‡ä»¶: {hdf5_file}")
        
        with h5py.File(hdf5_file, 'w') as f:
            # åˆ›å»ºæ•°æ®é›†ï¼Œä½¿ç”¨åˆ†å—å­˜å‚¨å’Œå‹ç¼©
            scalograms_dataset = f.create_dataset(
                'scalograms', 
                shape=(n_samples, n_scales, n_time_samples),
                dtype=np.float32,
                chunks=(min(batch_size, n_samples), n_scales, n_time_samples),
                compression='gzip',
                compression_opts=1  # è½»é‡å‹ç¼©ï¼Œå¹³è¡¡å‹ç¼©ç‡å’Œé€Ÿåº¦
            )
            
            # åˆ†æ‰¹å¤„ç†æ³¢å½¢
            print("  ğŸ”„ å¼€å§‹åˆ†æ‰¹å°æ³¢å˜æ¢...")
            
            for batch_idx in range(n_batches):
                start_idx = batch_idx * batch_size
                end_idx = min(start_idx + batch_size, n_samples)
                actual_batch_size = end_idx - start_idx
                
                print(f"    æ‰¹æ¬¡ {batch_idx+1}/{n_batches}: æ ·æœ¬ {start_idx}-{end_idx-1} ({actual_batch_size} ä¸ª)")
                
                # è·å–å½“å‰æ‰¹æ¬¡çš„æ³¢å½¢
                batch_waveforms = waveforms[start_idx:end_idx]
                
                # ä¸ºå½“å‰æ‰¹æ¬¡åˆå§‹åŒ–å°ºåº¦å›¾æ•°ç»„
                batch_scalograms = np.zeros((actual_batch_size, n_scales, n_time_samples), dtype=np.float32)
                
                # å¯¹å½“å‰æ‰¹æ¬¡åº”ç”¨å°æ³¢å˜æ¢
                for i, waveform in enumerate(batch_waveforms):
                    try:
                        # åº”ç”¨è¿ç»­å°æ³¢å˜æ¢
                        cwt_coefficients, _ = pywt.cwt(waveform, self.scales, self.wavelet_name)
                        
                        # è®¡ç®—å°ºåº¦å›¾ï¼ˆå–å¤æ•°ç³»æ•°çš„æ¨¡ï¼‰
                        scalogram = np.abs(cwt_coefficients)
                        batch_scalograms[i] = scalogram.astype(np.float32)
                        
                    except Exception as e:
                        print(f"      âš ï¸ æ ·æœ¬ {start_idx + i} å¤„ç†å¤±è´¥: {e}")
                        # ä½¿ç”¨é›¶å¡«å……
                        batch_scalograms[i] = np.zeros((n_scales, n_time_samples), dtype=np.float32)
                
                # å°†æ‰¹æ¬¡ç»“æœå†™å…¥HDF5æ–‡ä»¶
                scalograms_dataset[start_idx:end_idx] = batch_scalograms
                
                # æ¸…ç†å†…å­˜
                del batch_scalograms
                del batch_waveforms
                
                # æ˜¾ç¤ºè¿›åº¦
                progress = (batch_idx + 1) / n_batches * 100
                print(f"      è¿›åº¦: {progress:.1f}%")
        
        print("  âœ… åˆ†æ‰¹å°æ³¢å˜æ¢å®Œæˆï¼")
        
        # é‡æ–°åŠ è½½å®Œæ•´æ•°æ®é›†è¿›è¡Œåç»­å¤„ç†ï¼ˆåªåŠ è½½å…ƒæ•°æ®ï¼‰
        print("  ğŸ“Š åŠ è½½å®Œæ•´å°ºåº¦å›¾æ•°æ®...")
        
        with h5py.File(hdf5_file, 'r') as f:
            # åªåŠ è½½å‰å‡ ä¸ªæ ·æœ¬ç”¨äºå±•ç¤ºï¼Œä¸åŠ è½½å…¨éƒ¨
            sample_scalograms = f['scalograms'][:min(1000, n_samples)]
        
        # åˆ›å»ºå°ºåº¦å›¾æ•°æ®é›†å…ƒæ•°æ®
        self.scalograms_dataset = {
            'scalograms_file': hdf5_file,  # ä¿å­˜æ–‡ä»¶è·¯å¾„è€Œä¸æ˜¯æ•°æ®
            'n_samples': n_samples,
            'shape': (n_samples, n_scales, n_time_samples),
            'csi_labels': csi_labels,
            'metadata': metadata,
            'scales': self.scales,
            'frequencies': self.frequencies,
            'time_axis': np.arange(n_time_samples) * (1.0 / self.sampling_rate),
            'transform_params': {
                'wavelet': self.wavelet_name,
                'sampling_rate': self.sampling_rate,
                'freq_range': self.target_freq_range,
                'n_scales': n_scales
            }
        }
        
        print(f"  ğŸ“Š å°ºåº¦å›¾æ•°æ®é›†å½¢çŠ¶: {(n_samples, n_scales, n_time_samples)}")
        print(f"  ğŸ’¾ æ•°æ®ä¿å­˜åœ¨: {hdf5_file}")
        print(f"  ğŸ•’ æ—¶é—´è½´èŒƒå›´: 0 - {self.scalograms_dataset['time_axis'][-1]*1000:.1f} ms")
        print(f"  ğŸ“» é¢‘ç‡è½´èŒƒå›´: {self.frequencies.min():.1f} Hz - {self.frequencies.max()/1000:.1f} kHz")
        
        # ä½¿ç”¨æ ·æœ¬æ•°æ®è¿›è¡Œå¯è§†åŒ–
        self._visualize_sample_scalograms_from_hdf5(sample_scalograms)
        
        # æ¸…ç†æ ·æœ¬æ•°æ®
        del sample_scalograms
    
    def _visualize_sample_scalograms_from_hdf5(self, sample_scalograms):
        """å¯è§†åŒ–å‡ ä¸ªæ ·æœ¬çš„å°ºåº¦å›¾ï¼ˆä»HDF5æ•°æ®ï¼‰"""
        print("  æ­£åœ¨ç”Ÿæˆæ ·æœ¬å°ºåº¦å›¾å¯è§†åŒ–...")
        
        # æ£€æŸ¥frequenciesæ˜¯å¦å·²ç»åˆå§‹åŒ–
        if self.frequencies is None:
            print("  é”™è¯¯ï¼šé¢‘ç‡å°šæœªåˆå§‹åŒ–ï¼è¯·å…ˆè°ƒç”¨design_wavelet_scales()æ–¹æ³•")
            return
        
        csi_labels = self.scalograms_dataset['csi_labels']
        time_axis_ms = self.scalograms_dataset['time_axis'] * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        frequencies_khz = self.frequencies / 1000  # è½¬æ¢ä¸ºkHz
        
        # é€‰æ‹©ä¸åŒCSIç­‰çº§çš„æ ·æœ¬
        low_csi_idx = np.argmin(csi_labels)  # æœ€å¥½çš„èƒ¶ç»“
        high_csi_idx = np.argmax(csi_labels)  # æœ€å·®çš„èƒ¶ç»“
        medium_csi_idx = np.argmin(np.abs(csi_labels - np.median(csi_labels)))  # ä¸­ç­‰èƒ¶ç»“
        
        sample_indices = [low_csi_idx, medium_csi_idx, high_csi_idx]
        sample_titles = [
            f'Good Bond (CSI={csi_labels[low_csi_idx]:.3f})',
            f'Medium Bond (CSI={csi_labels[medium_csi_idx]:.3f})',
            f'Poor Bond (CSI={csi_labels[high_csi_idx]:.3f})'
        ]
        
        fig, axes = plt.subplots(3, 2, figsize=(15, 12))
        fig.suptitle('Sample Scalograms from CWT Analysis', fontsize=16)
        
        for i, (idx, title) in enumerate(zip(sample_indices, sample_titles)):
            # åŸå§‹æ³¢å½¢
            ax = axes[i, 0]
            original_waveform = self.analyzer.target_builder.model_dataset['waveforms'][idx]
            ax.plot(time_axis_ms, original_waveform, 'b-', linewidth=1)
            ax.set_xlabel('Time (ms)')
            ax.set_ylabel('Amplitude')
            ax.set_title(f'Original Waveform - {title}')
            ax.grid(True, alpha=0.3)
            ax.set_xlim(0, 4)  # èšç„¦äº0-4 ms
            
            # å°ºåº¦å›¾
            ax = axes[i, 1]
            scalogram = sample_scalograms[idx]
            
            # é™åˆ¶æ˜¾ç¤ºèŒƒå›´åˆ°0-4mså’Œ30kHzä»¥ä¸‹
            time_mask = time_axis_ms <= 4
            freq_mask = frequencies_khz <= 30
            
            display_scalogram = scalogram[freq_mask, :][:, time_mask]
            display_time = time_axis_ms[time_mask]
            display_freq = frequencies_khz[freq_mask]
            
            im = ax.imshow(display_scalogram, aspect='auto', cmap='jet',
                          extent=[display_time[0], display_time[-1], 
                                 display_freq[0], display_freq[-1]],
                          origin='lower')
            ax.set_xlabel('Time (ms)')
            ax.set_ylabel('Frequency (kHz)')
            ax.set_title(f'Scalogram - {title}')
            
            # æ·»åŠ é¢œè‰²æ¡
            cbar = plt.colorbar(im, ax=ax)
            cbar.set_label('Magnitude')
        
        plt.tight_layout()
        plt.savefig('sample_scalograms.png', dpi=300, bbox_inches='tight')
        plt.show()
        print("  æ ·æœ¬å°ºåº¦å›¾å·²ä¿å­˜ä¸º sample_scalograms.png")
    
    def _visualize_sample_scalograms(self):
        """å¯è§†åŒ–å‡ ä¸ªæ ·æœ¬çš„å°ºåº¦å›¾ï¼ˆåŸç‰ˆæœ¬ï¼Œç”¨äºå…¼å®¹æ€§ï¼‰"""
        print("  æ­£åœ¨ç”Ÿæˆæ ·æœ¬å°ºåº¦å›¾å¯è§†åŒ–...")
        
        # æ£€æŸ¥frequenciesæ˜¯å¦å·²ç»åˆå§‹åŒ–
        if self.frequencies is None:
            print("  é”™è¯¯ï¼šé¢‘ç‡å°šæœªåˆå§‹åŒ–ï¼è¯·å…ˆè°ƒç”¨design_wavelet_scales()æ–¹æ³•")
            return
        
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨HDF5æ ¼å¼
        if 'scalograms_file' in self.scalograms_dataset:
            print("  æ£€æµ‹åˆ°HDF5æ ¼å¼æ•°æ®ï¼ŒåŠ è½½æ ·æœ¬è¿›è¡Œå¯è§†åŒ–...")
            try:
                import h5py
                with h5py.File(self.scalograms_dataset['scalograms_file'], 'r') as f:
                    sample_scalograms = f['scalograms'][:min(1000, self.scalograms_dataset['n_samples'])]
                self._visualize_sample_scalograms_from_hdf5(sample_scalograms)
                del sample_scalograms
                return
            except Exception as e:
                print(f"  âš ï¸ ä»HDF5åŠ è½½å¤±è´¥: {e}")
                return
        
        scalograms = self.scalograms_dataset['scalograms']
        csi_labels = self.scalograms_dataset['csi_labels']
        time_axis_ms = self.scalograms_dataset['time_axis'] * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        frequencies_khz = self.frequencies / 1000  # è½¬æ¢ä¸ºkHz
        
        # é€‰æ‹©ä¸åŒCSIç­‰çº§çš„æ ·æœ¬
        low_csi_idx = np.argmin(csi_labels)  # æœ€å¥½çš„èƒ¶ç»“
        high_csi_idx = np.argmax(csi_labels)  # æœ€å·®çš„èƒ¶ç»“
        medium_csi_idx = np.argmin(np.abs(csi_labels - np.median(csi_labels)))  # ä¸­ç­‰èƒ¶ç»“
        
        sample_indices = [low_csi_idx, medium_csi_idx, high_csi_idx]
        sample_titles = [
            f'Good Bond (CSI={csi_labels[low_csi_idx]:.3f})',
            f'Medium Bond (CSI={csi_labels[medium_csi_idx]:.3f})',
            f'Poor Bond (CSI={csi_labels[high_csi_idx]:.3f})'
        ]
        
        fig, axes = plt.subplots(3, 2, figsize=(15, 12))
        fig.suptitle('Sample Scalograms from CWT Analysis', fontsize=16)
        
        for i, (idx, title) in enumerate(zip(sample_indices, sample_titles)):
            # åŸå§‹æ³¢å½¢
            ax = axes[i, 0]
            original_waveform = self.analyzer.target_builder.model_dataset['waveforms'][idx]
            ax.plot(time_axis_ms, original_waveform, 'b-', linewidth=1)
            ax.set_xlabel('Time (ms)')
            ax.set_ylabel('Amplitude')
            ax.set_title(f'Original Waveform - {title}')
            ax.grid(True, alpha=0.3)
            ax.set_xlim(0, 4)  # èšç„¦äº0-4 ms
            
            # å°ºåº¦å›¾
            ax = axes[i, 1]
            scalogram = scalograms[idx]
            
            # é™åˆ¶æ˜¾ç¤ºèŒƒå›´åˆ°0-4mså’Œ30kHzä»¥ä¸‹
            time_mask = time_axis_ms <= 4
            freq_mask = frequencies_khz <= 30
            
            display_scalogram = scalogram[freq_mask, :][:, time_mask]
            display_time = time_axis_ms[time_mask]
            display_freq = frequencies_khz[freq_mask]
            
            im = ax.imshow(display_scalogram, aspect='auto', cmap='jet',
                          extent=[display_time[0], display_time[-1], 
                                 display_freq[0], display_freq[-1]],
                          origin='lower')
            ax.set_xlabel('Time (ms)')
            ax.set_ylabel('Frequency (kHz)')
            ax.set_title(f'Scalogram - {title}')
            
            # æ·»åŠ é¢œè‰²æ¡
            cbar = plt.colorbar(im, ax=ax)
            cbar.set_label('Magnitude')
        
        plt.tight_layout()
        plt.savefig('sample_scalograms.png', dpi=300, bbox_inches='tight')
        plt.show()
        print("  æ ·æœ¬å°ºåº¦å›¾å·²ä¿å­˜ä¸º sample_scalograms.png")
    
    def analyze_scalogram_statistics(self):
        """åˆ†æå°ºåº¦å›¾çš„ç»Ÿè®¡ç‰¹æ€§ - æ”¯æŒHDF5æ ¼å¼"""
        print("æ­£åœ¨åˆ†æå°ºåº¦å›¾ç»Ÿè®¡ç‰¹æ€§...")
        
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨HDF5æ ¼å¼
        if 'scalograms_file' in self.scalograms_dataset:
            print("  æ£€æµ‹åˆ°HDF5æ ¼å¼æ•°æ®ï¼Œè¿›è¡Œæ‰¹é‡ç»Ÿè®¡åˆ†æ...")
            self._analyze_scalogram_statistics_hdf5()
            return
        
        scalograms = self.scalograms_dataset['scalograms']
        csi_labels = self.scalograms_dataset['csi_labels']
        
        # è®¡ç®—å…¨å±€ç»Ÿè®¡
        print(f"  å°ºåº¦å›¾ç»Ÿè®¡:")
        print(f"    å½¢çŠ¶: {scalograms.shape}")
        print(f"    æ•°æ®ç±»å‹: {scalograms.dtype}")
        print(f"    å€¼èŒƒå›´: {scalograms.min():.3f} - {scalograms.max():.3f}")
        print(f"    å‡å€¼: {scalograms.mean():.3f} Â± {scalograms.std():.3f}")
        
        # æŒ‰CSIç­‰çº§åˆ†ç»„åˆ†æ
        csi_thresholds = [0.1, 0.3, 0.6]
        csi_groups = {
            'Excellent': csi_labels < csi_thresholds[0],
            'Good': (csi_labels >= csi_thresholds[0]) & (csi_labels < csi_thresholds[1]),
            'Fair': (csi_labels >= csi_thresholds[1]) & (csi_labels < csi_thresholds[2]),
            'Poor': csi_labels >= csi_thresholds[2]
        }
        
        print("\n  æŒ‰èƒ¶ç»“è´¨é‡åˆ†ç»„çš„å°ºåº¦å›¾ç‰¹æ€§:")
        for group_name, group_mask in csi_groups.items():
            if np.any(group_mask):
                group_scalograms = scalograms[group_mask]
                print(f"    {group_name}: {np.sum(group_mask)} ä¸ªæ ·æœ¬")
                print(f"      å‡å€¼: {group_scalograms.mean():.3f}")
                print(f"      æ ‡å‡†å·®: {group_scalograms.std():.3f}")
                print(f"      æœ€å¤§å€¼: {group_scalograms.max():.3f}")
        
        # åˆ†ææ—¶é¢‘åŸŸèƒ½é‡åˆ†å¸ƒ
        self._analyze_time_frequency_energy_distribution()
    
    def _analyze_scalogram_statistics_hdf5(self):
        """åˆ†æHDF5æ ¼å¼å°ºåº¦å›¾çš„ç»Ÿè®¡ç‰¹æ€§"""
        import h5py
        
        hdf5_file = self.scalograms_dataset['scalograms_file']
        csi_labels = self.scalograms_dataset['csi_labels']
        shape = self.scalograms_dataset['shape']
        
        print(f"  å°ºåº¦å›¾ç»Ÿè®¡:")
        print(f"    å½¢çŠ¶: {shape}")
        print(f"    æ•°æ®ç±»å‹: float32")
        print(f"    æ•°æ®æ–‡ä»¶: {hdf5_file}")
        
        # åˆ†æ‰¹è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        batch_size = 1000
        n_batches = (shape[0] + batch_size - 1) // batch_size
        
        # åˆå§‹åŒ–ç»Ÿè®¡å˜é‡
        total_sum = 0.0
        total_sum_sq = 0.0
        total_min = float('inf')
        total_max = float('-inf')
        total_count = 0
        
        print("  ğŸ“Š è®¡ç®—å…¨å±€ç»Ÿè®¡ä¿¡æ¯...")
        
        with h5py.File(hdf5_file, 'r') as f:
            scalograms_dataset = f['scalograms']
            
            for batch_idx in range(n_batches):
                start_idx = batch_idx * batch_size
                end_idx = min(start_idx + batch_size, shape[0])
                
                batch_data = scalograms_dataset[start_idx:end_idx]
                
                total_sum += np.sum(batch_data)
                total_sum_sq += np.sum(batch_data ** 2)
                total_min = min(total_min, np.min(batch_data))
                total_max = max(total_max, np.max(batch_data))
                total_count += batch_data.size
                
                if (batch_idx + 1) % 10 == 0:
                    print(f"    å¤„ç†æ‰¹æ¬¡: {batch_idx + 1}/{n_batches}")
        
        # è®¡ç®—æœ€ç»ˆç»Ÿè®¡
        mean = total_sum / total_count
        variance = (total_sum_sq / total_count) - (mean ** 2)
        std = np.sqrt(variance)
        
        print(f"    å€¼èŒƒå›´: {total_min:.3f} - {total_max:.3f}")
        print(f"    å‡å€¼: {mean:.3f} Â± {std:.3f}")
        
        # æŒ‰CSIç­‰çº§åˆ†ç»„åˆ†æï¼ˆç®€åŒ–ç‰ˆï¼‰
        csi_thresholds = [0.1, 0.3, 0.6]
        csi_groups = {
            'Excellent': csi_labels < csi_thresholds[0],
            'Good': (csi_labels >= csi_thresholds[0]) & (csi_labels < csi_thresholds[1]),
            'Fair': (csi_labels >= csi_thresholds[1]) & (csi_labels < csi_thresholds[2]),
            'Poor': csi_labels >= csi_thresholds[2]
        }
        
        print("\n  æŒ‰èƒ¶ç»“è´¨é‡åˆ†ç»„çš„æ ·æœ¬ç»Ÿè®¡:")
        for group_name, group_mask in csi_groups.items():
            if np.any(group_mask):
                print(f"    {group_name}: {np.sum(group_mask)} ä¸ªæ ·æœ¬")
        
        print("  â„¹ï¸ è¯¦ç»†çš„åˆ†ç»„å°ºåº¦å›¾ç»Ÿè®¡éœ€è¦å¤§é‡å†…å­˜ï¼Œå·²è·³è¿‡")
        print("  â„¹ï¸ æ—¶é¢‘åŸŸèƒ½é‡åˆ†å¸ƒåˆ†æéœ€è¦å¤§é‡å†…å­˜ï¼Œå·²è·³è¿‡")
    
    def _analyze_time_frequency_energy_distribution(self):
        """åˆ†ææ—¶é¢‘åŸŸèƒ½é‡åˆ†å¸ƒ"""
        print("  åˆ†ææ—¶é¢‘åŸŸèƒ½é‡åˆ†å¸ƒ...")
        
        scalograms = self.scalograms_dataset['scalograms']
        csi_labels = self.scalograms_dataset['csi_labels']
        time_axis_ms = self.scalograms_dataset['time_axis'] * 1000
        frequencies_khz = self.frequencies / 1000
        
        # è®¡ç®—ä¸åŒCSIç­‰çº§çš„å¹³å‡å°ºåº¦å›¾
        csi_low = csi_labels <= 0.2  # ä½CSIï¼ˆå¥½èƒ¶ç»“ï¼‰
        csi_high = csi_labels >= 0.6  # é«˜CSIï¼ˆå·®èƒ¶ç»“ï¼‰
        
        if np.any(csi_low) and np.any(csi_high):
            avg_scalogram_low = np.mean(scalograms[csi_low], axis=0)
            avg_scalogram_high = np.mean(scalograms[csi_high], axis=0)
            
            # è®¡ç®—å·®å¼‚å›¾
            scalogram_diff = avg_scalogram_high - avg_scalogram_low
            
            fig, axes = plt.subplots(2, 2, figsize=(15, 10))
            fig.suptitle('Time-Frequency Energy Distribution Analysis', fontsize=16)
            
            # é™åˆ¶æ˜¾ç¤ºèŒƒå›´
            time_mask = time_axis_ms <= 4
            freq_mask = frequencies_khz <= 30
            
            display_time = time_axis_ms[time_mask]
            display_freq = frequencies_khz[freq_mask]
            
            # å¥½èƒ¶ç»“å¹³å‡å°ºåº¦å›¾
            ax = axes[0, 0]
            im = ax.imshow(avg_scalogram_low[freq_mask, :][:, time_mask], 
                          aspect='auto', cmap='jet',
                          extent=[display_time[0], display_time[-1], 
                                 display_freq[0], display_freq[-1]],
                          origin='lower')
            ax.set_xlabel('Time (ms)')
            ax.set_ylabel('Frequency (kHz)')
            ax.set_title(f'Good Bond Average (CSI â‰¤ 0.2, n={np.sum(csi_low)})')
            plt.colorbar(im, ax=ax)
            
            # å·®èƒ¶ç»“å¹³å‡å°ºåº¦å›¾
            ax = axes[0, 1]
            im = ax.imshow(avg_scalogram_high[freq_mask, :][:, time_mask], 
                          aspect='auto', cmap='jet',
                          extent=[display_time[0], display_time[-1], 
                                 display_freq[0], display_freq[-1]],
                          origin='lower')
            ax.set_xlabel('Time (ms)')
            ax.set_ylabel('Frequency (kHz)')
            ax.set_title(f'Poor Bond Average (CSI â‰¥ 0.6, n={np.sum(csi_high)})')
            plt.colorbar(im, ax=ax)
            
            # å·®å¼‚å›¾
            ax = axes[1, 0]
            im = ax.imshow(scalogram_diff[freq_mask, :][:, time_mask], 
                          aspect='auto', cmap='RdBu_r',
                          extent=[display_time[0], display_time[-1], 
                                 display_freq[0], display_freq[-1]],
                          origin='lower')
            ax.set_xlabel('Time (ms)')
            ax.set_ylabel('Frequency (kHz)')
            ax.set_title('Difference (Poor - Good)')
            plt.colorbar(im, ax=ax, label='Magnitude Difference')
            
            # æ—¶é—´å’Œé¢‘ç‡ç»´åº¦çš„å¹³å‡èƒ½é‡
            ax = axes[1, 1]
            
            # æ—¶é—´ç»´åº¦å¹³å‡ï¼ˆæ‰€æœ‰é¢‘ç‡ï¼‰
            time_avg_low = np.mean(avg_scalogram_low, axis=0)
            time_avg_high = np.mean(avg_scalogram_high, axis=0)
            
            ax.plot(time_axis_ms, time_avg_low, 'b-', linewidth=2, label='Good Bond', alpha=0.7)
            ax.plot(time_axis_ms, time_avg_high, 'r-', linewidth=2, label='Poor Bond', alpha=0.7)
            ax.set_xlabel('Time (ms)')
            ax.set_ylabel('Average Magnitude')
            ax.set_title('Time Domain Average Energy')
            ax.set_xlim(0, 4)
            ax.legend()
            ax.grid(True, alpha=0.3)
            
            plt.tight_layout()
            plt.savefig('time_frequency_energy_analysis.png', dpi=300, bbox_inches='tight')
            plt.show()
            print("  æ—¶é¢‘èƒ½é‡åˆ†æå›¾å·²ä¿å­˜ä¸º time_frequency_energy_analysis.png")
    
    def save_scalogram_dataset(self, filepath='scalogram_dataset.npz'):
        """ä¿å­˜å°ºåº¦å›¾æ•°æ®é›†"""
        print(f"æ­£åœ¨ä¿å­˜å°ºåº¦å›¾æ•°æ®é›†åˆ° {filepath}...")
        
        # ä¿å­˜ä¸ºå‹ç¼©çš„npzæ–‡ä»¶
        np.savez_compressed(
            filepath,
            scalograms=self.scalograms_dataset['scalograms'],
            csi_labels=self.scalograms_dataset['csi_labels'],
            scales=self.scalograms_dataset['scales'],
            frequencies=self.scalograms_dataset['frequencies'],
            time_axis=self.scalograms_dataset['time_axis'],
            metadata_depth=self.scalograms_dataset['metadata']['depth'].values,
            metadata_receiver=self.scalograms_dataset['metadata']['receiver'].values,
            metadata_receiver_index=self.scalograms_dataset['metadata']['receiver_index'].values,
            **self.scalograms_dataset['transform_params']
        )
        
        print(f"  å°ºåº¦å›¾æ•°æ®é›†ä¿å­˜å®Œæˆ: {filepath}")
        
        # æ‰“å°æ–‡ä»¶å¤§å°ä¿¡æ¯
        import os
        file_size_mb = os.path.getsize(filepath) / (1024 * 1024)
        print(f"  æ–‡ä»¶å¤§å°: {file_size_mb:.1f} MB")
    
    @staticmethod
    def load_scalogram_dataset(filepath='scalogram_dataset.npz'):
        """åŠ è½½å°ºåº¦å›¾æ•°æ®é›†"""
        print(f"ä» {filepath} åŠ è½½å°ºåº¦å›¾æ•°æ®é›†...")
        
        data = np.load(filepath)
        
        scalogram_dataset = {
            'scalograms': data['scalograms'],
            'csi_labels': data['csi_labels'],
            'scales': data['scales'],
            'frequencies': data['frequencies'],
            'time_axis': data['time_axis'],
            'metadata': {
                'depth': data['metadata_depth'],
                'receiver': data['metadata_receiver'],
                'receiver_index': data['metadata_receiver_index']
            },
            'transform_params': {
                'wavelet': str(data['wavelet']),
                'sampling_rate': float(data['sampling_rate']),
                'freq_range': tuple(data['freq_range']),
                'n_scales': int(data['n_scales'])
            }
        }
        
        print(f"  åŠ è½½å®Œæˆï¼Œå°ºåº¦å›¾å½¢çŠ¶: {scalogram_dataset['scalograms'].shape}")
        return scalogram_dataset


def add_wavelet_transform_to_analyzer():
    """å°†å°æ³¢å˜æ¢åŠŸèƒ½æ·»åŠ åˆ°ä¸»åˆ†æå™¨"""
    
    def run_wavelet_transform_section(self):
        """è¿è¡Œç¬¬4èŠ‚ï¼šé€šè¿‡è¿ç»­å°æ³¢å˜æ¢è¿›è¡Œæ—¶é¢‘åˆ†è§£"""
        print("\nç¬¬4èŠ‚ï¼šé€šè¿‡è¿ç»­å°æ³¢å˜æ¢è¿›è¡Œæ—¶é¢‘åˆ†è§£")
        print("-"*40)
        
        # åˆ›å»ºå°æ³¢å˜æ¢å¤„ç†å™¨
        wavelet_processor = WaveletTransformProcessor(self)
        
        try:
            # 4.1 & 4.2 è®¾è®¡å°æ³¢å°ºåº¦
            wavelet_processor.design_wavelet_scales()
            
            # 4.3 åº”ç”¨CWTç”Ÿæˆå°ºåº¦å›¾æ•°æ®é›†
            wavelet_processor.apply_cwt_to_dataset()
            
            # åˆ†æå°ºåº¦å›¾ç»Ÿè®¡ç‰¹æ€§
            wavelet_processor.analyze_scalogram_statistics()
            
            # ä¿å­˜å°ºåº¦å›¾æ•°æ®é›†
            wavelet_processor.save_scalogram_dataset()
            
            # å°†wavelet_processorå­˜å‚¨åˆ°analyzerä¸­ä¾›åç»­ä½¿ç”¨
            self.wavelet_processor = wavelet_processor
            
            print("\nç¬¬4èŠ‚å®Œæˆï¼")
            
        except Exception as e:
            print(f"ç¬¬4èŠ‚æ‰§è¡Œå¤±è´¥: {e}")
            raise
    
    # å°†æ–¹æ³•åŠ¨æ€æ·»åŠ åˆ°CementChannelingAnalyzerç±»
    from main_analysis import CementChannelingAnalyzer
    CementChannelingAnalyzer.run_wavelet_transform_section = run_wavelet_transform_section 